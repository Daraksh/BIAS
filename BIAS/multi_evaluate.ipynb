{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(csv_path, is_binary=True, num=2):\n",
    "    '''\n",
    "    Calculate average accuracy, accuracy per skin type, PQD, DPM, EOM.\n",
    "    All known skin types.\n",
    "    Input: val results csv path, type_indices: a list\n",
    "    Output: a dictionary with 'acc_avg', 'acc_per_type', 'PQD', 'DPM', 'EOM'\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Calculate the number of groups based on Fitzpatrick types\n",
    "    num_groups = (6 - 1) // num + 1\n",
    "\n",
    "    # Create arrays to store the results\n",
    "    labels_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    correct_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    predictions_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    positive_list = []  # For binary classification probabilities\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        prediction = df.iloc[i]['prediction']\n",
    "        label = df.iloc[i]['label']\n",
    "        type_ = (df.iloc[i]['fitzpatrick'] - 1) // num\n",
    "        labels_array[int(type_), int(label)] += 1\n",
    "        predictions_array[int(type_), int(prediction)] += 1\n",
    "        if prediction == label:\n",
    "            correct_array[int(type_), int(label)] += 1\n",
    "\n",
    "        if is_binary:\n",
    "            if prediction == 0:\n",
    "                positive_list.append(1.0 - df.iloc[i]['prediction_probability'])\n",
    "            else:\n",
    "                positive_list.append(df.iloc[i]['prediction_probability'])\n",
    "    \n",
    "    # Avoid division by zero by adding checks and replacing zero values with small positive constants\n",
    "    eps = 1e-6  # Small constant to avoid zero values\n",
    "    \n",
    "    correct_array_sumc = np.sum(correct_array, axis=1)\n",
    "    labels_array_sumc = np.sum(labels_array, axis=1)\n",
    "    acc_array = np.divide(correct_array_sumc, labels_array_sumc + eps)\n",
    "\n",
    "    avg_acc = np.sum(correct_array) / (np.sum(labels_array) + eps)\n",
    "    \n",
    "    # PQD: Compute min/max accuracy safely\n",
    "    acc_min = np.min(acc_array[acc_array > 0]) if np.any(acc_array > 0) else eps\n",
    "    acc_max = np.max(acc_array) if np.max(acc_array) > 0 else eps\n",
    "    PQD = acc_min / acc_max\n",
    "\n",
    "    # DPM: Compute demo_array and ensure no zero division\n",
    "    demo_array = np.divide(predictions_array, np.sum(predictions_array, axis=1, keepdims=True) + eps)\n",
    "    demo_min = np.min(demo_array, axis=0)\n",
    "    demo_max = np.max(demo_array, axis=0)\n",
    "    DPM = np.mean(np.divide(demo_min, demo_max + eps))\n",
    "\n",
    "    # EOM: Compute element-wise equality of opportunity\n",
    "    eo_array = np.divide(correct_array, labels_array + eps)\n",
    "    eo_min = np.min(eo_array, axis=0)\n",
    "    eo_max = np.max(eo_array, axis=0)\n",
    "    EOM = np.mean(np.divide(eo_min, eo_max + eps))\n",
    "\n",
    "    # Calculate AUC for binary classification\n",
    "    AUC = -1\n",
    "    if is_binary:\n",
    "        fpr, tpr, _ = roc_curve(df['label'], positive_list, drop_intermediate=True)\n",
    "        AUC = auc(fpr, tpr)\n",
    "\n",
    "    return {\n",
    "        'acc_avg': avg_acc, \n",
    "        'acc_per_type': acc_array.tolist(),  # Convert numpy array to list for readability\n",
    "        'PQD': PQD, \n",
    "        'DPM': DPM, \n",
    "        'EOM': EOM, \n",
    "        'AUC': AUC\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(csv_path, is_binary=True, num=2):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    num_groups = (6 - 1) // num + 1\n",
    "\n",
    "    labels_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    correct_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    predictions_array = np.zeros((num_groups, len(df['label'].unique())))\n",
    "    acc_array = np.zeros(num_groups)\n",
    "\n",
    "    group_probs = [[] for _ in range(num_groups)]\n",
    "    group_labels = [[] for _ in range(num_groups)]\n",
    "\n",
    "    positive_list = []\n",
    "    global_labels = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        prediction = df.iloc[i]['prediction']\n",
    "        label = df.iloc[i]['label']\n",
    "        prob = df.iloc[i]['prediction_probability']\n",
    "        type_ = (df.iloc[i]['fitzpatrick'] - 1) // num\n",
    "\n",
    "        labels_array[type_, int(label)] += 1\n",
    "        predictions_array[type_, int(prediction)] += 1\n",
    "        if prediction == label:\n",
    "            correct_array[type_, int(label)] += 1\n",
    "\n",
    "        if is_binary:\n",
    "            prob_pos = prob if prediction == 1 else 1.0 - prob\n",
    "            positive_list.append(prob_pos)\n",
    "            global_labels.append(label)\n",
    "\n",
    "            group_probs[type_].append(prob)\n",
    "            group_labels[type_].append(label)\n",
    "\n",
    "    eps = 1e-6\n",
    "\n",
    "    correct_array_sumc = np.sum(correct_array, axis=1)\n",
    "    labels_array_sumc = np.sum(labels_array, axis=1)\n",
    "    acc_array = np.divide(correct_array_sumc, labels_array_sumc + eps)\n",
    "\n",
    "    avg_acc = np.sum(correct_array) / (np.sum(labels_array) + eps)\n",
    "\n",
    "    acc_min = np.min(acc_array[acc_array > 0]) if np.any(acc_array > 0) else eps\n",
    "    acc_max = np.max(acc_array) if np.max(acc_array) > 0 else eps\n",
    "    PQD = acc_min / acc_max\n",
    "\n",
    "    demo_array = np.divide(predictions_array, np.sum(predictions_array, axis=1, keepdims=True) + eps)\n",
    "    demo_min = np.min(demo_array, axis=0)\n",
    "    demo_max = np.max(demo_array, axis=0)\n",
    "    DPM = np.mean(np.divide(demo_min, demo_max + eps))\n",
    "\n",
    "    eo_array = np.divide(correct_array, labels_array + eps)\n",
    "    eo_min = np.min(eo_array, axis=0)\n",
    "    eo_max = np.max(eo_array, axis=0)\n",
    "    EOM = np.mean(np.divide(eo_min, eo_max + eps))\n",
    "\n",
    "    result = {\n",
    "        'acc_avg': avg_acc, \n",
    "        'acc_per_type': acc_array.tolist(), \n",
    "        'PQD': PQD, \n",
    "        'DPM': DPM, \n",
    "        'EOM': EOM\n",
    "    }\n",
    "\n",
    "    if is_binary:\n",
    "        # Global AUC\n",
    "        fpr, tpr, _ = roc_curve(global_labels, positive_list, drop_intermediate=True)\n",
    "        AUC = auc(fpr, tpr)\n",
    "        result['AUC'] = AUC\n",
    "\n",
    "        # Group-wise AUCs\n",
    "        aucs = []\n",
    "        tprs = []\n",
    "        fprs = []\n",
    "        for probs, labels in zip(group_probs, group_labels):\n",
    "            if len(set(labels)) < 2:\n",
    "                aucs.append(None)\n",
    "                tprs.append(None)\n",
    "                fprs.append(None)\n",
    "                continue\n",
    "            fpr_g, tpr_g, _ = roc_curve(labels, probs)\n",
    "            auc_g = auc(fpr_g, tpr_g)\n",
    "            aucs.append(auc_g)\n",
    "            tprs.append(tpr_g[1])  # TPR at first threshold (TP / (TP + FN))\n",
    "            fprs.append(fpr_g[1])  # FPR at first threshold (FP / (FP + TN))\n",
    "\n",
    "        valid_aucs = [a for a in aucs if a is not None]\n",
    "        result['min_auc'] = min(valid_aucs) if valid_aucs else None\n",
    "        result['max_auc'] = max(valid_aucs) if valid_aucs else None\n",
    "\n",
    "        # Equalized Odds Difference\n",
    "        tprs_valid = [t for t in tprs if t is not None]\n",
    "        fprs_valid = [f for f in fprs if f is not None]\n",
    "        if tprs_valid and fprs_valid:\n",
    "            eod = max(abs(max(tprs_valid) - min(tprs_valid)), abs(max(fprs_valid) - min(fprs_valid)))\n",
    "        else:\n",
    "            eod = None\n",
    "        result['EOD'] = eod\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary sensitive attribute value \n",
    "def cal_metrics(csv_path, is_binary=True):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    num_groups = 2  # Fixed since we only have Fitzpatrick types 1 and 2\n",
    "\n",
    "    label_classes = sorted(df['label'].unique())\n",
    "    num_classes = len(label_classes)\n",
    "\n",
    "    labels_array = np.zeros((num_groups, num_classes))\n",
    "    correct_array = np.zeros((num_groups, num_classes))\n",
    "    predictions_array = np.zeros((num_groups, num_classes))\n",
    "    acc_array = np.zeros(num_groups)\n",
    "\n",
    "    group_probs = [[] for _ in range(num_groups)]\n",
    "    group_labels = [[] for _ in range(num_groups)]\n",
    "\n",
    "    positive_list = []\n",
    "    global_labels = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        prediction = df.iloc[i]['prediction']\n",
    "        label = df.iloc[i]['label']\n",
    "        prob = df.iloc[i]['prediction_probability']\n",
    "        fitz = int(df.iloc[i]['fitzpatrick'])\n",
    "        type_ = fitz - 1  # Since fitzpatrick values are 1 or 2 â†’ type_ is 0 or 1\n",
    "\n",
    "        labels_array[type_, int(label)] += 1\n",
    "        predictions_array[type_, int(prediction)] += 1\n",
    "        if prediction == label:\n",
    "            correct_array[type_, int(label)] += 1\n",
    "\n",
    "        if is_binary:\n",
    "            prob_pos = prob if prediction == 1 else 1.0 - prob\n",
    "            positive_list.append(prob_pos)\n",
    "            global_labels.append(label)\n",
    "\n",
    "            group_probs[type_].append(prob)\n",
    "            group_labels[type_].append(label)\n",
    "\n",
    "    eps = 1e-6\n",
    "    acc_array = np.sum(correct_array, axis=1) / (np.sum(labels_array, axis=1) + eps)\n",
    "    avg_acc = np.sum(correct_array) / (np.sum(labels_array) + eps)\n",
    "\n",
    "    acc_min = np.min(acc_array[acc_array > 0]) if np.any(acc_array > 0) else eps\n",
    "    acc_max = np.max(acc_array) if np.max(acc_array) > 0 else eps\n",
    "    PQD = acc_min / acc_max\n",
    "\n",
    "    demo_array = np.divide(predictions_array, np.sum(predictions_array, axis=1, keepdims=True) + eps)\n",
    "    demo_min = np.min(demo_array, axis=0)\n",
    "    demo_max = np.max(demo_array, axis=0)\n",
    "    DPM = np.mean(np.divide(demo_min, demo_max + eps))\n",
    "\n",
    "    eo_array = np.divide(correct_array, labels_array + eps)\n",
    "    eo_min = np.min(eo_array, axis=0)\n",
    "    eo_max = np.max(eo_array, axis=0)\n",
    "    EOM = np.mean(np.divide(eo_min, eo_max + eps))\n",
    "\n",
    "    result = {\n",
    "        'acc_avg': avg_acc,\n",
    "        'acc_per_type': acc_array.tolist(),\n",
    "        'PQD': PQD,\n",
    "        'DPM': DPM,\n",
    "        'EOM': EOM\n",
    "    }\n",
    "\n",
    "    if is_binary:\n",
    "        fpr, tpr, _ = roc_curve(global_labels, positive_list)\n",
    "        AUC = auc(fpr, tpr)\n",
    "        result['AUC'] = AUC\n",
    "\n",
    "        aucs, tprs, fprs = [], [], []\n",
    "        for probs, labels in zip(group_probs, group_labels):\n",
    "            if len(set(labels)) < 2:\n",
    "                aucs.append(None)\n",
    "                tprs.append(None)\n",
    "                fprs.append(None)\n",
    "                continue\n",
    "            fpr_g, tpr_g, _ = roc_curve(labels, probs)\n",
    "            auc_g = auc(fpr_g, tpr_g)\n",
    "            aucs.append(auc_g)\n",
    "            tprs.append(tpr_g[1])\n",
    "            fprs.append(fpr_g[1])\n",
    "\n",
    "        valid_aucs = [a for a in aucs if a is not None]\n",
    "        result['min_auc'] = min(valid_aucs) if valid_aucs else None\n",
    "        result['max_auc'] = max(valid_aucs) if valid_aucs else None\n",
    "\n",
    "        tprs_valid = [t for t in tprs if t is not None]\n",
    "        fprs_valid = [f for f in fprs if f is not None]\n",
    "        if tprs_valid and fprs_valid:\n",
    "            eod = max(abs(max(tprs_valid) - min(tprs_valid)),\n",
    "                      abs(max(fprs_valid) - min(fprs_valid)))\n",
    "        else:\n",
    "            eod = None\n",
    "        result['EOD'] = eod\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage of above binary sensitive attribute \n",
    "#results = cal_metrics(\" \", is_binary=True)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d995bc54c9aaecfe64e6668cd10ce18771211a7298b34b6f0fab6698bea7d7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
